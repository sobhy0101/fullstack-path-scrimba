import { openai, supabase } from './config.js';

/* ============================================
LESSON 1: Creating and Storing Embeddings
============================================ */
/*

import podcasts from './content.js';

async function main(input) {
  const data = await Promise.all(
    input.map( async (textChunk) => {
        const embeddingResponse = await openai.embeddings.create({
            model: "text-embedding-ada-002",
            input: textChunk
        });
        return { 
          content: textChunk, 
          embedding: embeddingResponse.data[0].embedding 
        }
    })
  );
  
  // Insert content and embedding into Supabase
  await supabase.from('documents').insert(data); 
  console.log('Embedding and storing complete!');
}

// Make main accessible globally for manual testing
window.main = main;
window.podcasts = podcasts;

// Comment out to prevent auto-run on page load
// main(podcasts)

// Test code - uncomment to verify vector dimensions
const { data } = await supabase
  .from('documents')
  .select('embedding')
  .eq('id', 6)
  .single();

// Parse the vector string to an array
const embeddingArray = JSON.parse(data.embedding);
console.log('Vector dimensions:', embeddingArray.length); // Should be 1536
console.log('String length:', data.embedding.length);     // 19477 characters
*/

/* ============================================
   LESSON 2: Similarity Search with Embeddings
   ============================================ */

// User query about podcasts
// const query = "podcasts that are more than 60 minutes";
// main(query);

// /*
//   Create an embedding from the user input and return a 
//   semantically matching text chunk from the database 
// */
// async function main(input) {
//   // Create a vector embedding representing the input text
//   const embeddingResponse = await openai.embeddings.create({
//     model: "text-embedding-ada-002",
//     input,
//   }); 
  
//   // The vector generated by OpenAI
//   const embedding = embeddingResponse.data[0].embedding;
  
//   // Query Supabase for nearest vector match
//   const { data } = await supabase.rpc('match_documents', {
//     query_embedding: embedding,
//     match_threshold: 0.50,
//     match_count: 1
//   });
//   console.log(data[0].content, data[0].similarity);
// }


/* ============================================
   LESSON 3: Create a conversational response using OpenAI
   ============================================ */


// User query about podcasts
const query = "An episode Elon Musk would enjoy";
main(query);

// Bring all function calls together
async function main(input) {
  const embedding = await createEmbedding(input);
  const match = await findNearestMatch(embedding);
  await getChatCompletion(match, input);
}

// Create an embedding vector representing the input text
async function createEmbedding(input) {
  const embeddingResponse = await openai.embeddings.create({
    model: "text-embedding-ada-002",
    input
  });
  return embeddingResponse.data[0].embedding;
}

// Query Supabase and return a semantically matching text chunk
async function findNearestMatch(embedding) {
  const { data } = await supabase.rpc('match_documents', {
    query_embedding: embedding,
    match_threshold: 0.50,
    match_count: 1
  });
  return data[0].content;
}

// Use OpenAI to make the response conversational
const chatMessages = [{
    role: 'system',
    content: `You are an enthusiastic podcast expert who loves recommending podcasts to people. You will be given two pieces of information - some context about podcasts episodes and a question. Your main job is to formulate a short answer to the question using the provided context. If you are unsure and cannot find the answer in the context, say, "Sorry, I don't know the answer." Please do not make up the answer.` 
}];

async function getChatCompletion(text, query) {
  chatMessages.push({
    role: 'user',
    content: `Context: ${text} Question: ${query}`
  });
  
  const response = await openai.chat.completions.create({
    model: 'gpt-4',
    messages: chatMessages,
    temperature: 0.5,
    frequency_penalty: 0.5
  });

  console.log(response.choices[0].message.content);
}